{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://www.clipartkey.com/mpngs/m/196-1966407_national-data-science-bowl-data-science-bowl-logo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  <center>Imagine accelerating research on almost all diseases, from lung cancer and heart disease to rare diseases. Data Science Bowl offers our most ambitious mission: to create an algorithm for automatic detection of cores.</center>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center>This dataset contains a large number of segmented nuclei images. The images were acquired under a variety of conditions and vary in the cell type, magnification, and imaging modality (brightfield vs. fluorescence). The dataset is designed to challenge an algorithm's ability to generalize across these variations</center> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " -------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-29T20:00:43.416437Z",
     "iopub.status.busy": "2023-04-29T20:00:43.416082Z",
     "iopub.status.idle": "2023-04-29T20:00:49.476733Z",
     "shell.execute_reply": "2023-04-29T20:00:49.475471Z",
     "shell.execute_reply.started": "2023-04-29T20:00:43.416356Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import cv2\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "\n",
    "from tensorflow.keras.layers import Input, concatenate, Conv2D, MaxPooling2D, UpSampling2D, Dropout\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-29T20:01:33.939300Z",
     "iopub.status.busy": "2023-04-29T20:01:33.938609Z",
     "iopub.status.idle": "2023-04-29T20:01:43.169444Z",
     "shell.execute_reply": "2023-04-29T20:01:43.168525Z",
     "shell.execute_reply.started": "2023-04-29T20:01:33.939263Z"
    }
   },
   "outputs": [],
   "source": [
    "with zipfile.ZipFile(\"../input/data-science-bowl-2018/stage1_train.zip\",'r') as z:\n",
    "    z.extractall(\"stage1_train\")\n",
    "\n",
    "with zipfile.ZipFile(\"../input/data-science-bowl-2018/stage2_test_final.zip\",'r') as z:\n",
    "    z.extractall(\"stage2_test_final\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-29T20:01:30.894090Z",
     "iopub.status.busy": "2023-04-29T20:01:30.893182Z",
     "iopub.status.idle": "2023-04-29T20:01:30.898090Z",
     "shell.execute_reply": "2023-04-29T20:01:30.897168Z",
     "shell.execute_reply.started": "2023-04-29T20:01:30.894051Z"
    }
   },
   "outputs": [],
   "source": [
    "train_path = '/kaggle/working/stage1_train/'\n",
    "test_path = '/kaggle/working/stage2_test_final/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-29T20:01:28.368563Z",
     "iopub.status.busy": "2023-04-29T20:01:28.368179Z",
     "iopub.status.idle": "2023-04-29T20:01:28.376062Z",
     "shell.execute_reply": "2023-04-29T20:01:28.375112Z",
     "shell.execute_reply.started": "2023-04-29T20:01:28.368516Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dir = os.listdir(train_path)\n",
    "test_dir = os.listdir(test_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "---------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Loading data</center>\n",
    "\n",
    "![](https://www.grantauto.ru/include/section_loader.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's create empty tensors for future images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-22T23:44:58.753157Z",
     "iopub.status.busy": "2022-02-22T23:44:58.752788Z",
     "iopub.status.idle": "2022-02-22T23:44:58.761039Z",
     "shell.execute_reply": "2022-02-22T23:44:58.760345Z",
     "shell.execute_reply.started": "2022-02-22T23:44:58.753117Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = np.zeros((len(train_dir), 256, 256, 3), dtype=np.uint8)\n",
    "Y_train = np.zeros((len(train_dir), 256, 256, 1), dtype=bool)\n",
    "\n",
    "X_test = np.zeros((len(test_dir), 256, 256, 3), dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The directory structure looks like each **Spot Nuclei** has its own folder.\n",
    "\n",
    "The folder with **id Spot Nuclei** contains two folders: **images** and **masks**\n",
    "\n",
    "images contains the original **Spot Nuclei image**. We need to write it **into a pre-created tensor X**\n",
    "\n",
    "masks contains several images with **different parts of the masks**. We need to **merge all the masks into one image** using **np.maximum**. Further, just as with the original image, write to the **pre-created tensor Y**\n",
    "\n",
    "We will **compress all images** to a size of **256x256x3**, however, we will set the size of **mask images** to **256x256x1**, since it makes no sense for us to store them in **rgb format**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-22T23:44:58.763388Z",
     "iopub.status.busy": "2022-02-22T23:44:58.763134Z",
     "iopub.status.idle": "2022-02-22T23:45:23.640025Z",
     "shell.execute_reply": "2022-02-22T23:45:23.639239Z",
     "shell.execute_reply.started": "2022-02-22T23:44:58.763355Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "for i, name in enumerate(train_dir):\n",
    "    path = train_path + name\n",
    "    img_real = cv2.imread(path+'/images/'+ name +'.png')\n",
    "    img_real = cv2.resize(img_real,(256,256))\n",
    "    X_train[i] = img_real\n",
    "    \n",
    "    img_segment_full = np.zeros((256, 256 , 1), dtype=bool)\n",
    "    segment_path = path+'/masks/'\n",
    "    for name in os.listdir(segment_path):\n",
    "        img_segment = cv2.imread(segment_path + name, 0)\n",
    "        img_segment = cv2.resize(img_segment, (256, 256))\n",
    "        img_segment = np.expand_dims(img_segment, axis=-1)\n",
    "        img_segment_full = np.maximum(img_segment_full, img_segment)\n",
    "    \n",
    "    Y_train[i] = img_segment_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-22T23:45:23.641861Z",
     "iopub.status.busy": "2022-02-22T23:45:23.641438Z",
     "iopub.status.idle": "2022-02-22T23:45:36.165467Z",
     "shell.execute_reply": "2022-02-22T23:45:36.163965Z",
     "shell.execute_reply.started": "2022-02-22T23:45:23.641822Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "for i, name in enumerate(test_dir):\n",
    "    path = test_path + name\n",
    "    img_real = cv2.imread(path+'/images/'+ name +'.png')\n",
    "    img_real = cv2.resize(img_real, (256,256))\n",
    "    X_test[i] = img_real"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, let's see the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-22T23:45:36.167281Z",
     "iopub.status.busy": "2022-02-22T23:45:36.166605Z",
     "iopub.status.idle": "2022-02-22T23:45:36.596907Z",
     "shell.execute_reply": "2022-02-22T23:45:36.596261Z",
     "shell.execute_reply.started": "2022-02-22T23:45:36.167242Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,8))\n",
    "plt.subplot(121)\n",
    "plt.imshow(X_train[2])\n",
    "plt.title('Real image')\n",
    "plt.subplot(122)\n",
    "plt.imshow(Y_train[2])\n",
    "plt.title('Segmentation image');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good, now let's work on augmenting our images\n",
    "\n",
    "\n",
    "--------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  <center>Data Preprocessing</center>\n",
    "\n",
    "\n",
    "![](https://iprofi.kg/wp-content/uploads/2021/07/60ffd0153c1d3549690580.gif)\n",
    "\n",
    "\n",
    "-------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**U-net** does not require a large amount of data, as for example for the classification task, however, there are only **670 data** in the train, I believe that **augmentation** here can improve the segmentation result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-22T23:45:36.59807Z",
     "iopub.status.busy": "2022-02-22T23:45:36.597832Z",
     "iopub.status.idle": "2022-02-22T23:45:36.605102Z",
     "shell.execute_reply": "2022-02-22T23:45:36.604167Z",
     "shell.execute_reply.started": "2022-02-22T23:45:36.598038Z"
    }
   },
   "outputs": [],
   "source": [
    "aug_gen_args = dict(shear_range = 0.2,\n",
    "                    zoom_range = 0.2,\n",
    "                    rotation_range=40,\n",
    "                    width_shift_range=0.2,\n",
    "                    height_shift_range=0.2,\n",
    "                    horizontal_flip=True,\n",
    "                    vertical_flip=True,\n",
    "                    fill_mode='reflect'\n",
    "                   )\n",
    "\n",
    "X_train_gen = ImageDataGenerator(**aug_gen_args)\n",
    "y_train_gen = ImageDataGenerator(**aug_gen_args)\n",
    "X_val_gen = ImageDataGenerator()\n",
    "y_val_gen = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin with, let's demonstrate on one image what augmentation looks like.\n",
    "\n",
    "It is important to set the **seed** and **shuffle=False** in order for the **original augmented images** to match the **segmented augmented images**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-22T23:45:36.609674Z",
     "iopub.status.busy": "2022-02-22T23:45:36.609209Z",
     "iopub.status.idle": "2022-02-22T23:45:36.614859Z",
     "shell.execute_reply": "2022-02-22T23:45:36.614137Z",
     "shell.execute_reply.started": "2022-02-22T23:45:36.609637Z"
    }
   },
   "outputs": [],
   "source": [
    "aug_image_real = X_train[5].reshape((1,)+X_train[1].shape)\n",
    "aug_image_seg = Y_train[5].reshape((1,)+Y_train[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-22T23:45:36.616589Z",
     "iopub.status.busy": "2022-02-22T23:45:36.616312Z",
     "iopub.status.idle": "2022-02-22T23:45:36.624185Z",
     "shell.execute_reply": "2022-02-22T23:45:36.623581Z",
     "shell.execute_reply.started": "2022-02-22T23:45:36.616554Z"
    }
   },
   "outputs": [],
   "source": [
    "aug_image_real_check = X_train_gen.flow(aug_image_real, batch_size=1, seed=17, shuffle=False)\n",
    "aug_image_seg_check = y_train_gen.flow(aug_image_seg, batch_size=1, seed=17, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-22T23:45:36.625481Z",
     "iopub.status.busy": "2022-02-22T23:45:36.625261Z",
     "iopub.status.idle": "2022-02-22T23:45:37.559755Z",
     "shell.execute_reply": "2022-02-22T23:45:37.559072Z",
     "shell.execute_reply.started": "2022-02-22T23:45:36.625457Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "plt.subplot(141)\n",
    "plt.imshow(X_train[5])\n",
    "plt.title(\"original\")\n",
    "i=2\n",
    "for batch in aug_image_real_check:\n",
    "    plt.subplot(14*10+i)\n",
    "    plt.imshow(image.array_to_img(batch[0]))\n",
    "    plt.title(\"augmented\")\n",
    "    i += 1\n",
    "    if i % 5 == 0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-22T23:45:37.561176Z",
     "iopub.status.busy": "2022-02-22T23:45:37.5608Z",
     "iopub.status.idle": "2022-02-22T23:45:38.081918Z",
     "shell.execute_reply": "2022-02-22T23:45:38.081226Z",
     "shell.execute_reply.started": "2022-02-22T23:45:37.56114Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "plt.subplot(141)\n",
    "plt.imshow(Y_train[5])\n",
    "plt.title(\"original\")\n",
    "i=2\n",
    "for batch in aug_image_seg_check:\n",
    "    plt.subplot(14*10+i)\n",
    "    plt.imshow(image.array_to_img(batch[0]))\n",
    "    plt.title(\"augmented\")\n",
    "    i += 1\n",
    "    if i % 5 == 0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good, now let's split **X_train** into **2 parts**: **train** and **val**. For val of the selection, select **0.1 data size**\n",
    "\n",
    "Next, **apply the augmentation generators** to the train data; no augmentation will be performed for the val data\n",
    "\n",
    "Since we need to do augmentation for original images and segmented images, then we **need to combine the generators** into one using the **zip()**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-22T23:45:38.083843Z",
     "iopub.status.busy": "2022-02-22T23:45:38.083354Z",
     "iopub.status.idle": "2022-02-22T23:45:38.142451Z",
     "shell.execute_reply": "2022-02-22T23:45:38.141706Z",
     "shell.execute_reply.started": "2022-02-22T23:45:38.083793Z"
    }
   },
   "outputs": [],
   "source": [
    "train, val, y_train, y_val = train_test_split(X_train, Y_train, test_size=0.1, random_state=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-22T23:45:38.14422Z",
     "iopub.status.busy": "2022-02-22T23:45:38.143955Z",
     "iopub.status.idle": "2022-02-22T23:45:48.596491Z",
     "shell.execute_reply": "2022-02-22T23:45:48.595763Z",
     "shell.execute_reply.started": "2022-02-22T23:45:38.144184Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_gen.fit(train, augment=True, seed=17)\n",
    "y_train_gen.fit(y_train, augment=True, seed=17)\n",
    "X_val_gen.fit(val, seed=17)\n",
    "y_val_gen.fit(y_val, seed=17)\n",
    "\n",
    "X_train_generator = X_train_gen.flow(train, batch_size=16, seed=17, shuffle=False)\n",
    "y_train_generator = y_train_gen.flow(y_train, batch_size=16, seed=17, shuffle=False)\n",
    "X_val_generator = X_val_gen.flow(val, batch_size=16, seed=17, shuffle=False)\n",
    "y_val_generator = y_val_gen.flow(y_val, batch_size=16, seed=17, shuffle=False)\n",
    "\n",
    "train_generator = zip(X_train_generator, y_train_generator)\n",
    "val_generator = zip(X_val_generator, y_val_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, now let's create a custom metric that is required in this competition\n",
    "\n",
    "\n",
    "--------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  <center>Creating custom metric and loss</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IoU metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This competition is evaluated on the mean average precision at different intersection over union (IoU) thresholds.\n",
    "\n",
    "I have seen implementations in other kernels, they all use the built-in **tf.keras.metrics.MeanIoU** function to calculate **IoU**, and then average the results over **thresholds of 0.05**.\n",
    "\n",
    "I'm not sure that it works correctly and I tried to implement my own version of the **MeanIoU** metric for the competition.\n",
    "\n",
    "First, I wrote a function to calculate IoU:\n",
    "\n",
    "1) Calculate intersection\n",
    "2) Calculate union\n",
    "\n",
    "**P.S** In many IoU implementations on the Internet, I have not seen people subtract intersection from union, however, I think this is necessary, since we sum the intersection part 2 times instead of one. In this way, we stick with the set.union() implementation for sets.\n",
    "\n",
    "**!!!!CORRECT ME IF I AM WRONG!!!!**\n",
    "\n",
    "3) Calculate intersection/union\n",
    "\n",
    "![](https://images.viblo.asia/1f53756b-5271-4d27-824c-180043f47ebe.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate **mean_iou**, we calculate the **IoU for each threshold using a loop**, passing **t_y_pred** of type **float32**\n",
    "\n",
    "**P.S** I don’t know why, but the model reports an error if we pass any other data type to it, although we still get int values at the output\n",
    "\n",
    "**!!!!!CORRECT ME IF I AM WRONG!!!!!**\n",
    "\n",
    "after counting the values of all threshold values t, we **average and return the result**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-22T23:45:48.598162Z",
     "iopub.status.busy": "2022-02-22T23:45:48.597926Z",
     "iopub.status.idle": "2022-02-22T23:45:48.603428Z",
     "shell.execute_reply": "2022-02-22T23:45:48.602701Z",
     "shell.execute_reply.started": "2022-02-22T23:45:48.598128Z"
    }
   },
   "outputs": [],
   "source": [
    "def iou(y_true, y_pred):\n",
    "    intersection = K.sum(K.abs(y_true * y_pred), axis=[1,2,3])\n",
    "    union = K.sum(y_true, axis=[1,2,3]) + K.sum(y_pred, axis=[1,2,3]) - intersection\n",
    "    iou = K.mean((intersection + 1) / (union + 1), axis=0)\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-22T23:45:48.605203Z",
     "iopub.status.busy": "2022-02-22T23:45:48.604749Z",
     "iopub.status.idle": "2022-02-22T23:45:48.613655Z",
     "shell.execute_reply": "2022-02-22T23:45:48.612949Z",
     "shell.execute_reply.started": "2022-02-22T23:45:48.605167Z"
    }
   },
   "outputs": [],
   "source": [
    "def mean_iou(y_true, y_pred):\n",
    "    results = []   \n",
    "    for t in np.arange(0.5, 1, 0.05):\n",
    "        t_y_pred = tf.cast((y_pred > t), tf.float32)\n",
    "        pred = iou(y_true, t_y_pred)\n",
    "        results.append(pred)\n",
    "        \n",
    "    return K.mean(K.stack(results), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dice loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also for U-net, **dice_loss** or **binary crossentropy** is most often used, in this work I tried to use **dise_loss**\n",
    "\n",
    "However, **IoU_loss** could also be used, but as I understand it, this metric **cannot be differentiated**\n",
    "\n",
    "**!!!!!CORRECT ME IF I AM WRONG!!!!!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://fooobar.com/img/e7683d03a1e317c73bdbaafd343803d3.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-22T23:45:48.61491Z",
     "iopub.status.busy": "2022-02-22T23:45:48.614671Z",
     "iopub.status.idle": "2022-02-22T23:45:48.62356Z",
     "shell.execute_reply": "2022-02-22T23:45:48.622868Z",
     "shell.execute_reply.started": "2022-02-22T23:45:48.614879Z"
    }
   },
   "outputs": [],
   "source": [
    "def dice_loss(y_true, y_pred):\n",
    "    intersection = K.sum(K.abs(y_true * y_pred), axis=[1,2,3])\n",
    "    union = K.sum(y_true, axis=[1,2,3]) + K.sum(y_pred, axis=[1,2,3])\n",
    "    dice = K.mean((2. * intersection + 1) / (union + 1), axis=0)\n",
    "    return 1. - dice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, now let's write the basic architecture of the model\n",
    "\n",
    "\n",
    "-------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  <center>U-NET model</center>\n",
    "\n",
    "![](https://www.mdpi.com/remotesensing/remotesensing-11-02970/article_deploy/html/images/remotesensing-11-02970-g001-550.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. We feed the **Input() layer** with the size of the input images to the **U-NET input**, then using **Lambda** we **normalize** our image to a network-friendly range **(0:1)**\n",
    "\n",
    "U-net architecture can be divided into two parts: **encoder and decoder**\n",
    "\n",
    "2. **ENCODER**\n",
    "\n",
    " encoder is a typical CNN architecture. It consists of:\n",
    "\n",
    "* encoder consists of reapplying **Conv2D 3x3**;\n",
    "* In order not to lose border pixels during convolution, we use **padding**;\n",
    "* On each layer we apply **ReLU activation**;\n",
    "* Next comes **MaxPooling2D 2x2** for downsampling;\n",
    "* At each encoder step, the filter channels are doubled, we'll **start at 32 and end at 512**;\n",
    "\n",
    "3. **DECODER**\n",
    "\n",
    "Each step in the expanding path consists of a property map upsampling operation. It consists of:\n",
    "\n",
    "* **UpSampling2D 2×2**, which reduces the number of filter channels;\n",
    "* **concatenate** to link layers to the same property map;\n",
    "* Re-apply **Conv2D 3×3**;\n",
    "* In order not to lose border pixels during convolution, we use **padding**;\n",
    "* On each layer we apply **ReLU activation**;\n",
    "* At each step of the encoder, the filter channels are halved, we will **start at 512 and end at 32**;\n",
    "\n",
    "\n",
    "4. The last layer uses **Conv2D 1x1** to map each feature vector to the **desired class**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-22T23:45:48.626028Z",
     "iopub.status.busy": "2022-02-22T23:45:48.62579Z",
     "iopub.status.idle": "2022-02-22T23:45:51.216964Z",
     "shell.execute_reply": "2022-02-22T23:45:51.216276Z",
     "shell.execute_reply.started": "2022-02-22T23:45:48.626002Z"
    }
   },
   "outputs": [],
   "source": [
    "inputs = Input((256, 256, 3))\n",
    "s = tf.keras.layers.Lambda(lambda x: x/255.0)(inputs)\n",
    "\n",
    "conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
    "conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\n",
    "pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\n",
    "conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\n",
    "pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\n",
    "conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n",
    "pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool3)\n",
    "conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv4)\n",
    "pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "\n",
    "conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool4)\n",
    "conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv5)\n",
    "conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv5)\n",
    "\n",
    "up6 = UpSampling2D(size=(2,2))(conv5)\n",
    "up6 = concatenate([up6, conv4])\n",
    "conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(up6)\n",
    "conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv6)\n",
    "\n",
    "up7 = UpSampling2D(size=(2,2))(conv6)\n",
    "up7 = concatenate([up7, conv3])\n",
    "conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(up7)\n",
    "conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv7)\n",
    "\n",
    "up8 = UpSampling2D(size=(2,2))(conv7)\n",
    "up8 = concatenate([up8, conv2])\n",
    "conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(up8)\n",
    "conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv8)\n",
    "\n",
    "up9 = UpSampling2D(size=(2,2))(conv8)\n",
    "up9 = concatenate([up9, conv1])\n",
    "conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(up9)\n",
    "conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv9)\n",
    "\n",
    "conv10 = Conv2D(1, (1, 1), activation='sigmoid')(conv9)\n",
    "\n",
    "model = models.Model(inputs=[inputs], outputs=[conv10])\n",
    "\n",
    "model.compile(optimizer=optimizers.Adam(learning_rate=2e-4), loss=dice_loss, metrics=mean_iou)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "using **optimizer='Adam'** as the most basic and recommended, but for **better accuracy**, I **lowered the learning_rate**\n",
    "\n",
    "**loss='dice_loss'** we defined it with the **dice_loss** function earlier\n",
    "\n",
    "**metrics='mean_iou'** we defined it with the **mean_iou** function earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-22T23:45:51.218711Z",
     "iopub.status.busy": "2022-02-22T23:45:51.218467Z",
     "iopub.status.idle": "2022-02-22T23:45:51.239728Z",
     "shell.execute_reply": "2022-02-22T23:45:51.239064Z",
     "shell.execute_reply.started": "2022-02-22T23:45:51.218678Z"
    }
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  <center>U-net model training</center>\n",
    "\n",
    "---------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](http://mianbaoban-assets.oss-cn-shenzhen.aliyuncs.com/2020/2/Yzaemm.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, now let's start training our model.\n",
    "\n",
    "Pass **train and val generators**\n",
    "\n",
    "Set the **train/val epoch size** as **len(train/val)/bath_size**\n",
    "\n",
    "Let's set **epochs=25**, I think this is enough to get good results\n",
    "\n",
    "P.S. I won't use callbacks as a model with such a small amount of data and 25 epochs will learn quickly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-22T23:45:51.241582Z",
     "iopub.status.busy": "2022-02-22T23:45:51.241335Z",
     "iopub.status.idle": "2022-02-22T23:56:26.810877Z",
     "shell.execute_reply": "2022-02-22T23:56:26.810128Z",
     "shell.execute_reply.started": "2022-02-22T23:45:51.241548Z"
    }
   },
   "outputs": [],
   "source": [
    "history = model.fit(train_generator,\n",
    "                    steps_per_epoch=len(train)/8,\n",
    "                    validation_data=val_generator,\n",
    "                    validation_steps=len(val)/8,\n",
    "                    epochs=25\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-22T23:56:26.812969Z",
     "iopub.status.busy": "2022-02-22T23:56:26.812715Z",
     "iopub.status.idle": "2022-02-22T23:56:27.151875Z",
     "shell.execute_reply": "2022-02-22T23:56:27.151218Z",
     "shell.execute_reply.started": "2022-02-22T23:56:26.812935Z"
    }
   },
   "outputs": [],
   "source": [
    "loss = history.history['mean_iou']\n",
    "val_loss = history.history['val_mean_iou']\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.plot(loss, label='Train IOU')\n",
    "plt.plot(val_loss,'--', label='Val IOU')\n",
    "plt.title('Training and Validation mean IOU')\n",
    "plt.yticks(np.arange(0.5, 1, 0.05))\n",
    "plt.xticks(np.arange(0, 25))\n",
    "plt.grid()\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, we see that the average result for **Val_IoU is ~0.85** **Train_IoU ~0.8**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Let's take a look at the results in images\n",
    "\n",
    "------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#   <center>Result on train/val data</center> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-22T23:56:27.153708Z",
     "iopub.status.busy": "2022-02-22T23:56:27.153222Z",
     "iopub.status.idle": "2022-02-22T23:56:35.05454Z",
     "shell.execute_reply": "2022-02-22T23:56:35.05373Z",
     "shell.execute_reply.started": "2022-02-22T23:56:27.153669Z"
    }
   },
   "outputs": [],
   "source": [
    "train_pred = model.predict(train, verbose = 1)\n",
    "val_pred = model.predict(val, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-22T23:56:35.061748Z",
     "iopub.status.busy": "2022-02-22T23:56:35.059447Z",
     "iopub.status.idle": "2022-02-22T23:56:35.622242Z",
     "shell.execute_reply": "2022-02-22T23:56:35.62139Z",
     "shell.execute_reply.started": "2022-02-22T23:56:35.061705Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "plt.subplot(131)\n",
    "plt.imshow(train[1])\n",
    "plt.title('Original image')\n",
    "plt.subplot(132)\n",
    "plt.imshow(np.squeeze(y_train[1]))\n",
    "plt.title('Segmented image')\n",
    "plt.subplot(133)\n",
    "plt.imshow(np.squeeze(train_pred[1]))\n",
    "plt.title('Predicted  image');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-22T23:56:35.624132Z",
     "iopub.status.busy": "2022-02-22T23:56:35.623882Z",
     "iopub.status.idle": "2022-02-22T23:56:36.116855Z",
     "shell.execute_reply": "2022-02-22T23:56:36.116198Z",
     "shell.execute_reply.started": "2022-02-22T23:56:35.624099Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "plt.subplot(131)\n",
    "plt.imshow(val[3])\n",
    "plt.title('Original image')\n",
    "plt.subplot(132)\n",
    "plt.imshow(np.squeeze(y_val[3]))\n",
    "plt.title('Segmented image')\n",
    "plt.subplot(133)\n",
    "plt.imshow(np.squeeze(val_pred[3]))\n",
    "plt.title('Predicted  image');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, it looks like the neural network really works, now let's **predict** the result for **X_test data**.\n",
    "\n",
    "I won't be submitting on kaggle as the competition is over. The purpose of this notebook is to learn how to use **U-net for image segmentation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " -------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#   <center>Result on test data</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-22T23:56:36.11827Z",
     "iopub.status.busy": "2022-02-22T23:56:36.117919Z",
     "iopub.status.idle": "2022-02-22T23:56:45.75751Z",
     "shell.execute_reply": "2022-02-22T23:56:45.756744Z",
     "shell.execute_reply.started": "2022-02-22T23:56:36.118238Z"
    }
   },
   "outputs": [],
   "source": [
    "test_pred = model.predict(X_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-22T23:56:45.759086Z",
     "iopub.status.busy": "2022-02-22T23:56:45.758835Z",
     "iopub.status.idle": "2022-02-22T23:56:47.403777Z",
     "shell.execute_reply": "2022-02-22T23:56:47.402334Z",
     "shell.execute_reply.started": "2022-02-22T23:56:45.759049Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 32))\n",
    "for i in range(421, 429):\n",
    "    plt.subplot(i)\n",
    "    if i % 2!=0:\n",
    "        plt.imshow(X_test[i])\n",
    "        plt.title('Original image')\n",
    "    else:\n",
    "        plt.imshow(np.squeeze(test_pred[i-1]))\n",
    "        plt.title('Predicted image')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " --------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  <center>Thank you for watching this is my project, I will be grateful if you upvoted and give feedback about my work in the comments. I want to improve my skills, and if you find any mistakes in the work, please tell me about it. </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://data.whicdn.com/images/218833361/original.gif)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
