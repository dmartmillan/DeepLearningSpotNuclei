{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8c2d5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from IPython.display import Image as DPImage\n",
    "import os\n",
    "import numpy as np\n",
    "from random import sample\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import sklearn as sk\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import random\n",
    "import csv\n",
    "import skimage\n",
    "\n",
    "seed = 2023\n",
    "np.random.seed(seed)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f7c81bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_img(image, title=''):\n",
    "    plt.title(title)\n",
    "    plt.imshow(tf.keras.utils.array_to_img(image))\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "6a20d81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "isImageGrayscale = lambda img: all(map(lambda p: p[0] == p[1] == p[2], img.getdata()))\n",
    "                                   \n",
    "def preprocessAndStoreImages(data_dir, image_dir, save_dir, contrast_ratio = 1.5, threshold = 0.6):\n",
    "    image_ids = os.listdir(data_dir)\n",
    "    for _, imgID in enumerate(image_ids):\n",
    "        full_img_dir = f'{data_dir}/{imgID}/{image_dir}'\n",
    "        \n",
    "        # Load Image\n",
    "        image = Image.open(f\"{full_img_dir}/{os.listdir(full_img_dir)[0]}\").convert('RGB')\n",
    "        grayscale = isImageGrayscale(image)\n",
    "        \n",
    "        # Convert to grayscale\n",
    "        image = np.array(image.convert('L'))\n",
    "        \n",
    "        # Invert Image if original was colored or background treshold is reached\n",
    "        if not grayscale or np.sum(image/255) > threshold*image.shape[0]*image.shape[1]:\n",
    "            image = 255 - image\n",
    "        \n",
    "        # Normalize\n",
    "        image = image - np.min(image)\n",
    "        if np.max(image) > 0:\n",
    "            image = np.round(image * (255 / np.max(image))).astype(np.uint8)\n",
    "            \n",
    "            # Increase Contrast\n",
    "            image = np.array(tf.image.adjust_contrast(image.reshape((*image.shape, 1)), contrast_ratio)).reshape(image.shape)\n",
    "        \n",
    "        # Save Preprocessed Image\n",
    "        save_path = f\"{data_dir}/{imgID}/{save_dir}\"\n",
    "        if not os.path.exists(save_path):\n",
    "            os.mkdir(save_path)\n",
    "        Image.fromarray(image, 'L').save(f\"{save_path}/{imgID}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "0b3fda2b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "preprocessAndStoreImages(\"./data/stage1_train\", \"images\", \"preprocessed_images\")\n",
    "preprocessAndStoreImages(\"./data/stage1_test\", \"images\", \"preprocessed_images\")\n",
    "preprocessAndStoreImages(\"./data/stage2_test_final\", \"images\", \"preprocessed_images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "cfd8364f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cropImages(data_dir, image_dir, save_dir, window_shape = (128, 128)):\n",
    "    image_ids = os.listdir(data_dir)\n",
    "    for tmp, imgID in enumerate(image_ids):\n",
    "        # Load Image\n",
    "        full_img_dir = f'{data_dir}/{imgID}/{image_dir}'\n",
    "        image = Image.open(f\"{full_img_dir}/{os.listdir(full_img_dir)[0]}\")\n",
    "        \n",
    "        # Create Save Dir\n",
    "        save_path = f\"{data_dir}/{imgID}/{save_dir}\"\n",
    "        if not os.path.exists(save_path):\n",
    "            os.mkdir(save_path)\n",
    "       \n",
    "        # Crop Image\n",
    "        i = 0\n",
    "        offset_y = 0\n",
    "        while offset_y < image.size[1]:\n",
    "            offset_x = 0\n",
    "            while offset_x < image.size[0]:\n",
    "                c = np.array(image.crop((\n",
    "                    offset_x, offset_y,\n",
    "                    window_shape[0] + offset_x if offset_x+window_shape[0] <= image.size[0] else image.size[0],\n",
    "                    window_shape[1] + offset_y if offset_y+window_shape[1] <= image.size[1] else image.size[1]\n",
    "                )))\n",
    "                X_tmp = np.zeros((window_shape[1], window_shape[0]), dtype=c.dtype)\n",
    "                X_tmp[:c.shape[0],:c.shape[1]] = c\n",
    "                \n",
    "                # Store cropping\n",
    "                Image.fromarray(X_tmp, 'L').save(f\"{save_path}/{i:03d}.png\")\n",
    "\n",
    "                i += 1\n",
    "                offset_x += window_shape[0]\n",
    "            offset_y += window_shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc3c073",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cropImages(\"./data/stage1_train\", \"preprocessed_images\", \"image_croppings\")\n",
    "cropImages(\"./data/stage1_train\", \"combined_masks\", \"mask_croppings\")\n",
    "\n",
    "cropImages(\"./data/stage1_test\", \"preprocessed_images\", \"image_croppings\")\n",
    "cropImages(\"./data/stage1_test\", \"combined_masks\", \"mask_croppings\")\n",
    "\n",
    "cropImages(\"./data/stage2_test_final\", \"preprocessed_images\", \"image_croppings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b945331",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
